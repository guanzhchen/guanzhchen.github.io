---
layout: page
---

### About Me

I am now a first-year PhD candidate at [National University of Singapore](https://nus.edu.sg/) (NUS), supervised by Dr. [Michael Qizhe Shieh](https://michaelshieh.com/).
<!-- second-year Master's student at [Sun Yat-sen University](https://www.sysu.edu.cn/) (SYSU), supervised by Dr. [Shangsong Liang](https://cse.sysu.edu.cn/content/4569). I also work closely with [Zaiqiao Meng](https://mengzaiqiao.github.io/) and [Fangyu Liu](https://fangyuliu.me/about.html).
Previously, I completed my Bachelor's degree at [Chongqing University](https://www.cqu.edu.cn/) (CQU) in 2021. -->
I am pursuing my passion for advancing the edge intelligence of large language models (LLMs).
My research specifically focuses on enhancing LLMs' context understanding capabilities, covering

- effective and efficient long-context modeling with new architecture(s);
- Unified multimodal context.




### News
- ***Feb 2025:*** We release the [LongPO](https://www.arxiv.org/pdf/2502.13922), a self-evolving long-context LLM training approach for both context extension and long-context alignment in one stage without external annotation.
- ***Feb 2025:*** [LongPO](https://www.arxiv.org/pdf/2502.13922) has been accepted to ICLR 2025!
- ***Jan 2024:*** [CLEX](https://arxiv.org/abs/2310.16450) has been accepted to ICLR 2024!
- ***Oct 2023:*** We release the [CLEX](https://arxiv.org/abs/2310.16450), a length extrapolation method that enables LLMs to access the context length up to 4x~8x the training length!


### Preprint


- [RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding](https://arxiv.org/abs/2502.20330)<br>
  Guanzheng Chen\*, Qilong Feng\*, Jinjie Ni, Xin Li, Michael Qizhe Shieh
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2502.20330" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/John-AI-Lab/RAPID" target="_blank" rel="noopener">Code</a>
  </div>




### Publications

- [LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization](https://arxiv.org/abs/2502.13922)<br>
  **Guanzheng Chen**, Xin Li, Michael Qizhe Shieh, Lidong Bing.<br>
 The Thirteenth International Conference on Learning Representations ([ICLR'25](https://iclr.cc/))
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.arxiv.org/pdf/2502.13922" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/DAMO-NLP-SG/LongPO" target="_blank" rel="noopener">Code</a>
  </div>


- [VCD: Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2311.16922)<br>
 Sicong Leng, Hang Zhang, **Guanzheng Chen**, Xin Li, Shijian Lu, Chunyan Miao, Lidong Bing.<br>
 The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024 ([CVPR'24](https://cvpr.thecvf.com/Conferences/2024))
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2311.16922" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/DAMO-NLP-SG/VCD" target="_blank" rel="noopener">Code</a>
  </div>



- [CLEX: Continuous Length Extrapolation for Large Language Models](https://arxiv.org/pdf/2310.16450.pdf)<br>
  **Guanzheng Chen**, Xin Li, Zaiqiao Meng, Shangsong Liang, Lidong Bing.<br>
 The Twelfth International Conference on Learning Representations ([ICLR'24](https://iclr.cc/))
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2310.16450.pdf" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/DAMO-NLP-SG/CLEX" target="_blank" rel="noopener">Code</a>
  </div>


- [Revisiting Parameter-Efficient Tuning: Are We Really There Yet?](https://arxiv.org/abs/2202.07962)<br>
  **Guanzheng Chen**, Fangyu Liu, Zaiqiao Meng, Shangsong Liang.<br>
  The 2022 Conference on Empirical Methods in Natural Language Processing ([EMNLP'22](https://2022.emnlp.org/), ***Oral Presentation***).
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2202.07962.pdf" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/guanzhchen/petuning" target="_blank" rel="noopener">Code</a>
  </div>

- [Multi-Relational Graph Representation Learning with Bayesian Gaussian Process Network](https://ojs.aaai.org/index.php/AAAI/article/view/20492)<br>
  **Guanzheng Chen**, Jinyuan Fang, Zaiqiao Meng, Qiang Zhang, Shangsong Liang.<br>
  Thirty-Sixth AAAI Conferene on Artificial Intelligence ([AAAI'22](https://aaai.org/Conferences/AAAI-22/)).<br>
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="{{site.url}}/data/papers/8491.ChenG_with_appendix.pdf" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/sysu-gzchen/GGPN" target="_blank" rel="noopener">Code</a>
  </div>

### Services

- Conference reviewer: [Neurips 2024](https://neurips.cc/Conferences/2024), [ICLR 2025](https://iclr.cc/), [ICML 2025](https://icml.cc/), [ACL Roling Review ](https://aclrollingreview.org/)

- Journal reviewer: [Neurocomputing](https://www.sciencedirect.com/journal/neurocomputing), [IEEE Transactions on Pattern Analysis and Machine Intelligence](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)