---
layout: page
---

### About Me

I am now a first-year PhD candidate at [National University of Singapore](https://nus.edu.sg/) (NUS). 
<!-- second-year Master's student at [Sun Yat-sen University](https://www.sysu.edu.cn/) (SYSU), supervised by Dr. [Shangsong Liang](https://cse.sysu.edu.cn/content/4569). I also work closely with [Zaiqiao Meng](https://mengzaiqiao.github.io/) and [Fangyu Liu](https://fangyuliu.me/about.html).
Previously, I completed my Bachelor's degree at [Chongqing University](https://www.cqu.edu.cn/) (CQU) in 2021. -->
My long-term research goal is to advance the field of NLP and make machines speak and write like humans with knowledge. Recently my research interests revolve around **large language models (LLMs)**, which comprises extremely large models (more than 100B, like GPT-3/4 series) and "smaller" counterparts (like LLaMA).
In particular, I am primarily working on

- enhancing the long-context capability of LLMs;
- utilising LLMs by parameter-efficient way;
- exploring the scaling ability of linear RNN (state-space model).<br>

I also spend some time focusing on knowledge injection and verification for LLMs.



### News
- ***Feb 2025:*** We release the [LongPO](https://www.arxiv.org/pdf/2502.13922), a self-evolving long-context LLM training approach for both context extension and long-context alignment in one stage without external annotation.
- ***Feb 2025:*** [LongPO](https://www.arxiv.org/pdf/2502.13922) has been accepted to ICLR 2025!
- ***Jan 2024:*** [CLEX](https://arxiv.org/abs/2310.16450) has been accepted to ICLR 2024!
- ***Oct 2023:*** We release the [CLEX](https://arxiv.org/abs/2310.16450), a length extrapolation method that enables LLMs to access the context length up to 4x~8x the training length! [[Tweets](https://twitter.com/gzchen3/status/1717584594533511553)]







### Publications

- [LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization](https://arxiv.org/abs/2502.13922)<br>
  **Guanzheng Chen**, Xin Li, Michael Qizhe Shieh, Lidong Bing.<br>
 The Thirteenth International Conference on Learning Representations ([ICLR'25](https://iclr.cc/))
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.arxiv.org/pdf/2502.13922" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/DAMO-NLP-SG/LongPO" target="_blank" rel="noopener">Code</a>
  </div>


- [CLEX: Continuous Length Extrapolation for Large Language Models](https://arxiv.org/pdf/2310.16450.pdf)<br>
  **Guanzheng Chen**, Xin Li, Zaiqiao Meng, Shangsong Liang, Lidong Bing.<br>
 The Twelfth International Conference on Learning Representations ([ICLR'24](https://iclr.cc/))
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2310.16450.pdf" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/DAMO-NLP-SG/CLEX" target="_blank" rel="noopener">Code</a>
  </div>


- [Revisiting Parameter-Efficient Tuning: Are We Really There Yet?](https://arxiv.org/abs/2202.07962)<br>
  **Guanzheng Chen**, Fangyu Liu, Zaiqiao Meng, Shangsong Liang.<br>
  The 2022 Conference on Empirical Methods in Natural Language Processing ([EMNLP'22](https://2022.emnlp.org/), ***Oral Presentation***).
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2202.07962.pdf" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/guanzhchen/petuning" target="_blank" rel="noopener">Code</a>
  </div>

- [Multi-Relational Graph Representation Learning with Bayesian Gaussian Process Network](https://ojs.aaai.org/index.php/AAAI/article/view/20492)<br>
  **Guanzheng Chen**, Jinyuan Fang, Zaiqiao Meng, Qiang Zhang, Shangsong Liang.<br>
  Thirty-Sixth AAAI Conferene on Artificial Intelligence ([AAAI'22](https://aaai.org/Conferences/AAAI-22/)).<br>
  
  <div class="btn-links">
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="{{site.url}}/data/papers/8491.ChenG_with_appendix.pdf" target="_blank" rel="noopener">PDF</a>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/sysu-gzchen/GGPN" target="_blank" rel="noopener">Code</a>
  </div>

### Services

- Conference reviewer: [SIGIR 2023](https://sigir.org/sigir2023/), [IJCAI 2023](https://ijcai-23.org/), [AAAI 2022](https://aaai.org/Conferences/AAAI-22/), [SDM 2022](https://www.siam.org/conferences/cm/conference/sdm22), [ACL Roling Review (Nov. 2022)](https://aclrollingreview.org/), [SIGIR 2022](https://sigir.org/sigir2022/)

- Journal reviewer: [Neurocomputing](https://www.sciencedirect.com/journal/neurocomputing), [Information Processing and Management](https://www.sciencedirect.com/journal/information-processing-and-management)